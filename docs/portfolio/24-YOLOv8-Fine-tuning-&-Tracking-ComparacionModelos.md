---
title: "Entrada ‚Äî Comparaci√≥n de Arquitecturas YOLO (YOLOv5n, YOLOv8n/s/m, YOLOv11n)"
date: 2025-12-08
---

# Entrada 24 ‚Äî Comparaci√≥n de Arquitecturas YOLO (YOLOv5n, YOLOv8n/s/m, YOLOv11n)

## Contexto
En esta tarea extra profundic√© en el an√°lisis comparativo de distintas arquitecturas YOLO modernas, evaluando su rendimiento en un mismo dataset de frutas previamente utilizado para el fine-tuning de YOLOv8.  
El objetivo principal fue entender los *trade-offs* reales entre modelos r√°pidos y livianos (nano) versus arquitecturas m√°s grandes y precisas (small, medium), as√≠ como contrastar modelos de distintas generaciones (YOLOv5 vs YOLOv8 vs YOLOv11).

Este tipo de an√°lisis refleja un escenario t√≠pico en aplicaciones reales de visi√≥n por computadora: elegir el detector m√°s conveniente seg√∫n el contexto (tiempo real, hardware limitado, m√°xima precisi√≥n, consumo energ√©tico, etc.).

---

## Objetivos
- Ejecutar **fine-tuning** de cinco modelos YOLO bajo las mismas condiciones.  
- Unificar m√©tricas comparativas: mAP@0.5, mAP@0.5:0.95, velocidad de inferencia y tama√±o del modelo.  
- Medir el costo computacional en GPU y tiempo de entrenamiento por arquitectura.  
- Analizar c√≥mo escalan precisi√≥n y velocidad al aumentar el tama√±o del modelo.  
- Producir visualizaciones que permitan interpretar los resultados de forma clara.  
- Formular recomendaciones justificadas para un escenario de producci√≥n.

---

## Actividades (con tiempos estimados)
- Instalaci√≥n, carga del dataset y verificaci√≥n de rutas ‚Äî 10 min  
- Configuraci√≥n del pipeline de entrenamiento ‚Äî 10 min  
- Fine-tuning de las cinco arquitecturas ‚Äî 50‚Äì60 min  
- C√°lculo de m√©tricas de desempe√±o e inferencia ‚Äî 20 min  
- Gr√°ficos comparativos: speed vs accuracy, mAP por clase ‚Äî 20 min  
- An√°lisis y reflexiones ‚Äî 20 min  

---

## Desarrollo
Comenc√© instalando **Ultralytics** y verificando la ruta del dataset `fruit_detection/Fruits-detection/data.yaml`.  
Luego defin√≠ un diccionario de arquitecturas:

- **YOLOv5n** (nano)  
- **YOLOv8n** (nano)  
- **YOLOv8s** (small)  
- **YOLOv8m** (medium)  
- **YOLOv11n** (nano, √∫ltima generaci√≥n)

A cada modelo le ejecut√© **fine-tuning durante 10 √©pocas**, usando los mismos hiperpar√°metros (`imgsz=416`, `batch=16`, `fraction=0.25`) para asegurar comparabilidad.  
Guard√©:

- m√©tricas de validaci√≥n (mAP@0.5, mAP@0.5:0.95)  
- tiempo de entrenamiento  
- tama√±o del archivo `.pt`  
- memoria m√°xima utilizada en GPU  
- tiempo de inferencia promedio por imagen  

Despu√©s gener√© gr√°ficos de:

- **Speed vs Accuracy** (ideal para ver trade-offs)  
- **mAP por clase**  
- **Curvas de p√©rdida** de entrenamiento  

Finalmente, constru√≠ una tabla consolidada con todos los modelos para interpretar sus diferencias en una sola vista.

---

## Resultados

### üî¢ Tabla comparativa de modelos

| Modelo     | mAP@0.5 | mAP@0.5:0.95 | Inference (ms) | Tama√±o (MB) | Training Time | GPU Usage |
|------------|---------|--------------|----------------|-------------|----------------|-----------|
| YOLOv5n    | 0.73    | 0.46         | ~3.1 ms/img    | ~4.5 MB     | Bajo           | Muy bajo  |
| YOLOv8n    | 0.78    | 0.51         | ~2.8 ms/img    | ~6.0 MB     | Bajo           | Bajo      |
| YOLOv8s    | 0.84    | 0.58         | ~4.1 ms/img    | ~21 MB      | Medio          | Medio     |
| YOLOv8m    | 0.88    | 0.63         | ~7.9 ms/img    | ~48 MB      | Alto           | Alto      |
| YOLOv11n   | 0.81    | 0.54         | ~2.5 ms/img    | ~7 MB       | Bajo           | Bajo      |

> Los valores corresponden al entrenamiento realizado sobre el dataset de frutas, manteniendo condiciones id√©nticas para cada arquitectura.

---

## An√°lisis de Resultados

### üîç Precisi√≥n (mAP)
- **YOLOv8m** obtuvo las mejores m√©tricas en ambas variantes de mAP.  
- **YOLOv8s** qued√≥ en segundo lugar, con una excelente relaci√≥n velocidad/precisi√≥n.  
- **YOLOv11n** mostr√≥ una mejora sobre YOLOv5n y un rendimiento similar a YOLOv8n, pero con menor tiempo de inferencia.  

### ‚ö° Velocidad de inferencia
- Los tres modelos *nano* (v5n, v8n, v11n) fueron notablemente m√°s r√°pidos.  
- **YOLOv11n** fue el m√°s veloz sin sacrificar demasiada precisi√≥n.  
- **YOLOv8m** fue el m√°s lento, como es esperable por su tama√±o.

### üß† Tama√±o del modelo
- Los modelos nano son extremadamente livianos (<10 MB).  
- Los modelos small y medium escalan r√°pidamente en tama√±o (+20 MB / +48 MB).  
- Los modelos m√°s grandes requieren m√°s memoria VRAM y mayor tiempo de entrenamiento.

### üìà Mapa Speed vs Accuracy
El gr√°fico mostr√≥ tres zonas claras:

1. **Ultra-r√°pidos** ‚Üí YOLOv11n, YOLOv8n  
2. **Equilibrados** ‚Üí YOLOv8s  
3. **M√°xima precisi√≥n pero costosos** ‚Üí YOLOv8m  

---

## Respuestas a las preguntas del trabajo

### **1Ô∏è‚É£ ¬øVale la pena usar modelos m√°s grandes para este dataset?**
En muchos casos, **no**.  
El dataset de frutas contiene objetos relativamente simples visualmente, por lo que un modelo *small* ya generaliza bien.  
YOLOv8m ofrece la mejor precisi√≥n, pero el incremento no justifica el costo computacional salvo que la aplicaci√≥n requiera m√°xima exactitud.

### **2Ô∏è‚É£ ¬øQu√© modelo recomendar√≠as para producci√≥n? ¬øPor qu√©?**
**YOLOv8s**, por tres razones:

- Excelente balance entre velocidad y precisi√≥n.  
- M√°s robusto que los modelos nano, especialmente en clases minoritarias.  
- F√°cil de desplegar incluso en hardware moderado (Jetson Nano, CPU potente, etc.).

Si la restricci√≥n principal fuera velocidad:  
‚Üí **YOLOv11n** ser√≠a la mejor elecci√≥n.

### **3Ô∏è‚É£ ¬øC√≥mo escala el inference time con el tama√±o del modelo?**
El tiempo de inferencia crece de forma **casi lineal** con el n√∫mero de par√°metros.  
Las diferencias entre v5 y v8 tambi√©n muestran mejoras de eficiencia de arquitectura.  
Los modelos peque√±os mantienen tiempos sub-5ms, mientras que los medianos superan los 7‚Äì8ms por imagen.

---

## Evidencias
https://colab.research.google.com/drive/1NgUKYGLodH3jsqTsA7yq_ejUVfUxl9Ob#scrollTo=wBbUr49hbmRe&uniqifier=1

---

## Reflexi√≥n
Este ejercicio me permiti√≥ comprender profundamente c√≥mo la elecci√≥n de arquitectura YOLO depende del contexto y no solo de la precisi√≥n.  
Los resultados muestran claramente que:

- Los modelos nano son ideales para inferencia en tiempo real y dispositivos IoT.  
- Los modelos small son la mejor opci√≥n generalista.  
- Los modelos medium ofrecen m√°xima precisi√≥n, pero su uso debe justificarse por requisitos espec√≠ficos.  
- YOLOv11n introduce mejoras en eficiencia y se perfila como un sucesor natural de v8n.

Adem√°s, pude reforzar el proceso completo de evaluaci√≥n comparativa:
entrenamiento controlado, recolecci√≥n de m√©tricas homog√©neas, an√°lisis de *trade-offs* y toma de decisiones basada en evidencia cuantitativa.

---

## Pr√≥ximos pasos
Proced√≠ a terminar las tareas de la UT5

