---
title: "Entrada ‚Äî YOLOv8 Fine-tuning & Tracking"
date: 2025-12-07
---

# Entrada 19 ‚Äî YOLOv8 Fine-tuning & Tracking

## Contexto
En este trabajo desarroll√© un pipeline completo de *object detection* y *object tracking* aplicado al dominio de **productos de supermercado**. El objetivo general fue demostrar que un modelo YOLOv8 pre-entrenado en COCO no es suficiente para detectar productos espec√≠ficos, y que un proceso de **fine-tuning** en un dataset especializado produce mejoras significativas en mAP, precisi√≥n, recall y calidad de los bounding boxes.  
La √∫ltima etapa consisti√≥ en aplicar el modelo fine-tuned al **tracking de frutas en video**, utilizando Norfair como motor de seguimiento basado en distancias euclidianas.

Este flujo es representativo de un caso real en retail: inventario autom√°tico, conteo de productos, monitoreo de l√≠neas de checkout y reposici√≥n en g√≥ndolas.

---

## Objetivos
- Implementar inferencia con YOLOv8 pre-entrenado en COCO.  
- Demostrar sus limitaciones en detecci√≥n de productos espec√≠ficos.  
- Descargar, analizar y visualizar un dataset de frutas en formato YOLO.  
- Ejecutar fine-tuning con YOLOv8n y evaluar m√©tricas (mAP, Precision, Recall).  
- Comparar modelo base vs modelo fine-tuned antes y despu√©s del entrenamiento.  
- Analizar errores (FP, FN, IoU, bounding boxes).  
- Aplicar el modelo fine-tuned a un sistema de tracking en video con Norfair.  
- Evaluar estabilidad de IDs, calidad del tracking y m√©tricas de duraci√≥n.  

---

## Actividades (con tiempos estimados)
- Instalaci√≥n y configuraci√≥n del entorno ‚Äî 10 min  
- Inferencia con YOLOv8 base ‚Äî 10 min  
- An√°lisis de limitaciones del modelo base ‚Äî 10 min  
- Descarga y exploraci√≥n del dataset de frutas ‚Äî 20 min  
- Visualizaci√≥n de anotaciones y distribuci√≥n de clases ‚Äî 20 min  
- Fine-tuning de YOLOv8 ‚Äî 40 min  
- Evaluaci√≥n de m√©tricas y comparaci√≥n antes/despu√©s ‚Äî 20 min  
- Implementaci√≥n de tracking con Norfair ‚Äî 30 min  
- An√°lisis de calidad del tracking ‚Äî 15 min  
- Reflexi√≥n final ‚Äî 10 min  

---

## Desarrollo
Inici√© cargando YOLOv8n pre-entrenado en COCO, realizando inferencia en im√°genes de pasillos de supermercado. Esto permiti√≥ comprobar que, aunque detecta clases gen√©ricas como *apple*, *banana* o *bottle*, no es capaz de distinguir productos espec√≠ficos ni variantes de frutas empaquetadas, lo que justifica el fine-tuning.

Luego descargu√© el **Fruit Detection Dataset**, verifiqu√© su estructura YOLO (train/valid + labels), analic√© la distribuci√≥n de clases y visualic√© ejemplos anotados. Identifiqu√© diferencias entre clases frecuentes y menos frecuentes, y c√≥mo esto podr√≠a impactar las m√©tricas posteriores.

Despu√©s ajust√© el `data.yaml`, configur√© hiperpar√°metros de entrenamiento y realic√© el **fine-tuning**. Durante el entrenamiento observ√© el comportamiento de `box_loss`, `cls_loss` y `dfl_loss`, as√≠ como la convergencia del modelo.  

Una vez entrenado, cargu√© el checkpoint `best.pt`, evalu√© m√©tricas en el validation set y compar√© resultados frente al modelo base. El modelo fine-tuned detect√≥ m√°s frutas, con bounding boxes m√°s precisos y scores de confianza m√°s altos.

Finalmente, apliqu√© el modelo fine-tuned a tracking en video utilizando **Norfair**, convirtiendo cada detecci√≥n en objetos `Detection` y configurando el tracker con par√°metros adecuados. Analic√© la estabilidad de los IDs, la continuidad de tracks y la distribuci√≥n de duraci√≥n de cada objeto a trav√©s del video.

---

## Evidencias
*https://colab.research.google.com/drive/1NgUKYGLodH3jsqTsA7yq_ejUVfUxl9Ob#scrollTo=ZK2y-gul8iBT*

---

## Reflexi√≥n

### Parte 1 ‚Äî Modelo Base (COCO)
- El modelo base detecta solo **clases gen√©ricas**, lo cual no es suficiente para retail.  
- Aunque COCO contenga ‚Äúapple‚Äù, eso no permite distinguir variedades o productos empaquetados.  
- El n√∫mero de clases (80) no incluye categor√≠as relevantes para un supermercado real.  
- Las detecciones suelen ser poco espec√≠ficas, y en muchos casos directamente ausentes.  

**Conclusi√≥n:** El fine-tuning es indispensable cuando el dominio contiene productos espec√≠ficos.

---

### Parte 2 ‚Äî Dataset y Fine-tuning

#### Distribuci√≥n de clases
- Algunas clases est√°n m√°s balanceadas que otras, lo que anticipa mejor mAP en las clases con m√°s instancias.  
- Las clases con menos ejemplos probablemente presentan m√°s FN.  
- Si agregara m√°s datos, priorizar√≠a las clases menos frecuentes para mejorar recall.

#### Visualizaci√≥n de anotaciones
- Los bounding boxes estaban bien definidos en la mayor√≠a de las im√°genes.  
- Se observ√≥ cierta variabilidad de iluminaci√≥n, fondos y tama√±os, lo cual favorece la generalizaci√≥n.  
- Ejemplos con frutas solapadas pueden generar dificultades para el modelo.

#### M√©tricas de training
- `box_loss` disminuy√≥ consistentemente, indicando mejor localizaci√≥n.  
- `cls_loss` se redujo, se√±alando mayor capacidad para distinguir clases.  
- `dfl_loss` baj√≥, lo que implica refinamiento en coordenadas.  
- La convergencia se alcanz√≥ antes de los √∫ltimos epochs, justificando usar un n√∫mero moderado como 10‚Äì20.

#### Hiperpar√°metros
- Usar fewer epochs reduce tiempo, aunque puede limitar capacidad de aprendizaje de clases raras.  
- Un tama√±o de imagen mayor podr√≠a mejorar precisi√≥n, pero con mayor costo computacional.  
- FRACTION=0.25 permite entrenar r√°pido y a√∫n as√≠ observar mejoras significativas, lo cual es √∫til en prototipos.  

---

### Parte 2 ‚Äî Comparaci√≥n Antes vs Despu√©s
- El modelo fine-tuned detect√≥ **muchas m√°s frutas** que el modelo base.  
- Las bounding boxes fueron m√°s precisas y con mayor confianza.  
- El modelo base produjo m√°s FP y FN, mientras que el fine-tuned redujo ambos.  
- Las clases con m√°s instancias en el dataset tuvieron mejor mAP.  
- mAP@0.5 mejor√≥ de forma notable, y mAP@0.5:0.95 mostr√≥ mejoras a√∫n m√°s pronunciadas al ser m√°s estricto.

**Conclusi√≥n:** El fine-tuning transform√≥ un modelo gen√©rico en un detector especializado, altamente superior para el dominio de frutas.

---

### Parte 3 ‚Äî Tracking con Norfair

#### Tracking en video
- El modelo fine-tuned permiti√≥ detectar frutas consistentemente frame a frame.  
- Los IDs se mantuvieron estables en la mayor√≠a de objetos, aunque hubo algunos switches ocasionales.  
- Las frutas m√°s grandes o con mayor contraste tuvieron tracking m√°s estable.  
- Las frutas peque√±as o parcialmente ocluidas presentaron interrupciones en su track.  

#### Par√°metros del tracker
- `distance_threshold` define tolerancia al movimiento; valores moderados mantuvieron la estabilidad.  
- `initialization_delay` ayud√≥ a evitar falsos tracks creados por ruido.  
- La duraci√≥n de los tracks permiti√≥ evaluar continuidad y estabilidad.  

**Conclusi√≥n:** La calidad del tracking depende tanto del modelo detector como de los par√°metros del tracker.

---

## üéØ Reflexi√≥n Final: Integraci√≥n del Assignment

---

## Sobre el Modelo

### ¬øCu√°l fue la mejora m√°s significativa del fine-tuning? (mAP, FPs, FNs)
La mejora m√°s significativa fue la reducci√≥n de *false negatives* y el incremento del *mAP*, lo que demuestra que el modelo realmente aprendi√≥ las caracter√≠sticas espec√≠ficas del dominio.

### ¬øEl modelo base (COCO) era completamente in√∫til o ten√≠a algo de valor?
El modelo base no era in√∫til: ten√≠a valor como punto de partida, pero era inadecuado para distinguir clases espec√≠ficas del dominio. Serv√≠a como ‚Äúesqueleto general‚Äù pero no como detector confiable.

### Si tuvieras que hacer fine-tuning para otro dominio (ej: piezas industriales), ¬øqu√© aprender√≠as de esta experiencia?
Aprend√≠ que, si el dominio tiene objetos bien definidos, repetir este pipeline (dataset ‚Üí limpieza ‚Üí fine-tuning ‚Üí evaluaci√≥n ‚Üí tracking) permite escalar el enfoque a casi cualquier industria.

---

## Sobre los Datos

### ¬ø8,479 im√°genes es mucho o poco para fine-tuning? ¬øPor qu√© funcion√≥ usar solo 25%?
8,479 im√°genes es un dataset razonable para fine-tuning. Funcionar con solo 25% fue posible porque las frutas tienen formas y texturas muy distintivas y el ruido visual es bajo en la mayor√≠a de las muestras.

### ¬øLa calidad de las anotaciones afect√≥ los resultados? ¬øC√≥mo lo sabes?
S√≠, la calidad de las anotaciones influy√≥ directamente: se observa que detecciones err√≥neas o bounding boxes mal posicionados generan errores consistentes en el modelo final.

### Si pudieras agregar 1,000 im√°genes m√°s, ¬øde qu√© tipo ser√≠an?
Agregar 1,000 im√°genes con:
- iluminaci√≥n dif√≠cil,  
- √°ngulos no vistos,  
- oclusiones parciales,  
ser√≠a ideal para mejorar robustez en escenarios exigentes.

---

## Sobre el Tracking

### ¬øQu√© fue m√°s importante para un buen tracking: el modelo o los par√°metros del tracker?
El modelo fue m√°s importante: un buen tracker no puede rastrear lo que no se detecta. La calidad del detector condiciona todo lo dem√°s.

### ¬øNorfair (IoU-based) es suficiente o necesitas algo m√°s sofisticado como DeepSORT?
Norfair es suficiente para escenarios simples, pero en entornos con muchas oclusiones o m√∫ltiples objetos similares, DeepSORT u otros m√©todos con re-identificaci√≥n ser√≠an necesarios.

### ¬øLos filtros de Kalman mejoraron la estabilidad del tracking? ¬øEn qu√© situaciones?
S√≠, especialmente cuando un objeto queda cubierto brevemente o se mueve r√°pido entre frames: el filtro predice la posici√≥n y evita saltos bruscos.

### ¬øEn qu√© escenarios fallar√≠a este sistema de tracking?
Falla cuando:
- los objetos se superponen por mucho tiempo,  
- la c√°mara se mueve bruscamente,  
- hay demasiados objetos similares,  
- o el detector pierde repetidamente instancias.

---

## Sobre el Deployment

### ¬øEste sistema podr√≠a correr en tiempo real? ¬øQu√© FPS necesitar√≠as?
S√≠, podr√≠a correr en tiempo real dependiendo del hardware. Para un supermercado o industria ligera, 20‚Äì30 FPS ser√≠an suficientes.

### ¬øQu√© optimizaciones har√≠as para producci√≥n? (modelo, c√≥digo, hardware)
- Exportaci√≥n a TensorRT o ONNX  
- Uso de modelos m√°s compactos  
- Cuantizaci√≥n  
- Pipeline as√≠ncrono para I/O y tracking  

### ¬øC√≥mo manejar√≠as casos extremos? (oclusiones, iluminaci√≥n, √°ngulos raros)
Con:
- aumentaci√≥n enfocada en condiciones extremas,  
- ajustes en thresholds,  
- validaci√≥n por m√∫ltiples frames,  
- modelos entrenados con iluminaci√≥n dif√≠cil y √°ngulos at√≠picos.

---

## Trade-offs y Decisiones

### Identifica 3 trade-offs clave que encontraste
1. **Speed vs Accuracy**: modelos peque√±os son r√°pidos pero menos precisos.  
2. **Epochs vs Tiempo de entrenamiento**: m√°s entrenamiento mejora resultados pero con retornos decrecientes.  
3. **Thresholds altos vs bajos**: thresholds altos reducen *false positives* pero aumentan *false negatives*.

### ¬øCu√°l fue la decisi√≥n m√°s importante que tomaste en los hyperpar√°metros?
Elegir un learning rate moderado y un n√∫mero de epochs reducido para evitar overfitting y acelerar iteraciones experimentales fue clave.

---

## Si tuvieras que explicar este proyecto a un stakeholder no-t√©cnico, ¬øqu√© 3 puntos destacar√≠as?

1. El sistema detecta productos con alta precisi√≥n y de manera autom√°tica.  
2. Puede rastrear cada objeto a lo largo del video, incluso si varios se mueven a la vez.  
3. Esto permite automatizar inventarios, monitoreo y an√°lisis operativos sin intervenci√≥n humana.

## Pr√≥ximos pasos
Proced√≠ a hacer la tarea 10 de la UT3, SAM Segmentation - Pretrained vs Fine-tuned



